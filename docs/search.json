[
  {
    "objectID": "posts/elt_omop/index.html",
    "href": "posts/elt_omop/index.html",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "",
    "text": "TL;DR You can find the project code on\n\nAirflow app\nDagster app\n\nshowcasing:\n\nFully functional real world ELT data pipeline to data science app orchestration with full observability (whole pipeline including DAGs inside dbt)\nRealistic healthcare data engineering workflow (Synthea to OMOP-CDM)\nOptions to choose job orchestration tools between Apache Airflow and Dagster\nData quality checks through Great Expectation and dbt tests.\n\nThis is Lei’s working portfolio project, illustrating a realistic data pipeline implemented from extracting electronic medical records (EMR), various medical vocabularies, loading onto a database, transforming data using dbt and further connecting to a BI tool Metabase and generating a data science report. while the workflow is orchestrated, scheduled and monitored with full oberverability using Apache airflow or Dagster.\n\nimport ssl\nimport graphviz\n\nfrom diagrams import Diagram, Cluster\nfrom diagrams.custom import Custom\nfrom urllib.request import urlretrieve\n\nfrom diagrams.onprem.analytics import Dbt\nfrom diagrams.onprem.workflow import Airflow\nfrom diagrams.generic.storage import Storage\nfrom diagrams.programming.language import Python\nfrom diagrams.onprem.analytics import Metabase\n\nssl._create_default_https_context = ssl._create_unverified_context\n\nwith Diagram(\"Synthea OMOP CDM ELT Workflow\", show=False) as diag:\n\n    # download the icon image file\n    dagster_url = \"https://dagster.io/images/brand/logos/dagster-primary-mark.png\"\n    dagster_icon = \"dagster-primary-mark.png\"\n    urlretrieve(dagster_url, dagster_icon)\n\n    \n    gx_url = \"https://images.ctfassets.net/ycwst8v1r2x5/jbrHhqGtdpbZFhki5MqBp/e6a5f6b567173b39430a1a18d060cb8e/gx_logo_horiz_color.png\"\n    gx_icon = \"gx-primary-mark.png\"\n    urlretrieve(gx_url, gx_icon)\n    \n\n    with Cluster(\"Orchestration & Scheduler\", direction=\"LR\"):    \n        orchestrator = [Airflow('Apache Airflow'),Custom(\"Dagster\", dagster_icon)]\n\n    with Cluster(\"Data Pipeline\"):\n        dbt = Dbt(\"dbt\") \n        duckdb = Custom(\"DuckDB\", \"DuckDB_Logo.png\")\n        storage = [Storage(\"Synthea \"), Storage(\"Athena Vocab\")] \n        gx = Custom(\"Great Expectations\", gx_icon)\n        storage &gt;&gt; gx &gt;&gt; duckdb &lt;&lt; dbt\n        duckdb &lt;&lt; Metabase(\"Metabase\")\n\n    with Cluster(\"Data Science App\"):\n\n        python = Python(\"Python\")\n\n        plotly_url = \"https://upload.wikimedia.org/wikipedia/commons/8/8a/Plotly-logo.png\"\n        plotly_icon = \"Plotly-logo.png\"\n        urlretrieve(plotly_url, plotly_icon)\n\n        plotly = Custom(\"Plotly\", plotly_icon)\n        python &gt;&gt; plotly\n\n\n    orchestrator &gt;&gt; dbt\n    orchestrator &gt;&gt; duckdb\n    orchestrator &gt;&gt; python\ndiag\n\nWarning: node 'f702db90456d4c2d95e9439299a8cbc5', graph 'Synthea OMOP CDM ELT Workflow' size too small for label"
  },
  {
    "objectID": "posts/elt_omop/index.html#introduction",
    "href": "posts/elt_omop/index.html#introduction",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "",
    "text": "TL;DR You can find the project code on\n\nAirflow app\nDagster app\n\nshowcasing:\n\nFully functional real world ELT data pipeline to data science app orchestration with full observability (whole pipeline including DAGs inside dbt)\nRealistic healthcare data engineering workflow (Synthea to OMOP-CDM)\nOptions to choose job orchestration tools between Apache Airflow and Dagster\nData quality checks through Great Expectation and dbt tests.\n\nThis is Lei’s working portfolio project, illustrating a realistic data pipeline implemented from extracting electronic medical records (EMR), various medical vocabularies, loading onto a database, transforming data using dbt and further connecting to a BI tool Metabase and generating a data science report. while the workflow is orchestrated, scheduled and monitored with full oberverability using Apache airflow or Dagster.\n\nimport ssl\nimport graphviz\n\nfrom diagrams import Diagram, Cluster\nfrom diagrams.custom import Custom\nfrom urllib.request import urlretrieve\n\nfrom diagrams.onprem.analytics import Dbt\nfrom diagrams.onprem.workflow import Airflow\nfrom diagrams.generic.storage import Storage\nfrom diagrams.programming.language import Python\nfrom diagrams.onprem.analytics import Metabase\n\nssl._create_default_https_context = ssl._create_unverified_context\n\nwith Diagram(\"Synthea OMOP CDM ELT Workflow\", show=False) as diag:\n\n    # download the icon image file\n    dagster_url = \"https://dagster.io/images/brand/logos/dagster-primary-mark.png\"\n    dagster_icon = \"dagster-primary-mark.png\"\n    urlretrieve(dagster_url, dagster_icon)\n\n    \n    gx_url = \"https://images.ctfassets.net/ycwst8v1r2x5/jbrHhqGtdpbZFhki5MqBp/e6a5f6b567173b39430a1a18d060cb8e/gx_logo_horiz_color.png\"\n    gx_icon = \"gx-primary-mark.png\"\n    urlretrieve(gx_url, gx_icon)\n    \n\n    with Cluster(\"Orchestration & Scheduler\", direction=\"LR\"):    \n        orchestrator = [Airflow('Apache Airflow'),Custom(\"Dagster\", dagster_icon)]\n\n    with Cluster(\"Data Pipeline\"):\n        dbt = Dbt(\"dbt\") \n        duckdb = Custom(\"DuckDB\", \"DuckDB_Logo.png\")\n        storage = [Storage(\"Synthea \"), Storage(\"Athena Vocab\")] \n        gx = Custom(\"Great Expectations\", gx_icon)\n        storage &gt;&gt; gx &gt;&gt; duckdb &lt;&lt; dbt\n        duckdb &lt;&lt; Metabase(\"Metabase\")\n\n    with Cluster(\"Data Science App\"):\n\n        python = Python(\"Python\")\n\n        plotly_url = \"https://upload.wikimedia.org/wikipedia/commons/8/8a/Plotly-logo.png\"\n        plotly_icon = \"Plotly-logo.png\"\n        urlretrieve(plotly_url, plotly_icon)\n\n        plotly = Custom(\"Plotly\", plotly_icon)\n        python &gt;&gt; plotly\n\n\n    orchestrator &gt;&gt; dbt\n    orchestrator &gt;&gt; duckdb\n    orchestrator &gt;&gt; python\ndiag\n\nWarning: node 'f702db90456d4c2d95e9439299a8cbc5', graph 'Synthea OMOP CDM ELT Workflow' size too small for label"
  },
  {
    "objectID": "posts/elt_omop/index.html#extraction-process",
    "href": "posts/elt_omop/index.html#extraction-process",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "Extraction process",
    "text": "Extraction process\nOpen sourced Synthea project provides the capability of generating realistic synthetic EMR data, and downloadable data in various formats. The csv files has been used in this project.\nAthena is one of the open sourced tools provided by OHDSI – Observational Health Data Sciences and Informatics, greatly simplied the process of converting various medical codes to standard codes. For this project, I downloaded a subset of the codes listed on the website.\nGreat Expectations were used for data quality checks. For illustration purpose, the Id in the patients csv file were checked for existence of null value."
  },
  {
    "objectID": "posts/elt_omop/index.html#loading-process",
    "href": "posts/elt_omop/index.html#loading-process",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "Loading process",
    "text": "Loading process\nBoth sets of datasets (csv format) were loaded to duckDB, orchestrated by workflow scheduler (Apache Airflow or Dagster)."
  },
  {
    "objectID": "posts/elt_omop/index.html#transformation-process",
    "href": "posts/elt_omop/index.html#transformation-process",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "Transformation process",
    "text": "Transformation process\ndbt were used for the whole transformation process. It is currently the stands for the T step in ETL/ELT process.\nThe sql codes were adopted from ETL-Synthea-dbt which in turn were adopted from OHDSI tool OHDSI/ETL-Synthea.\ndbt tests were used for each dbt models, as an example for data quality control.\nThis process is complex in nature. To have a good understanding, I went over following resources:\n\nThe Book of OHDSI\nOHDSI - YouTube\nData Standardization – OHDSI"
  },
  {
    "objectID": "posts/elt_omop/index.html#data-visualization-application",
    "href": "posts/elt_omop/index.html#data-visualization-application",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "Data Visualization Application",
    "text": "Data Visualization Application\nA BI Dashboard tool Metabase is connected to the database for interactive data visualization. \nAn interactive data visualization app using plotly is developped. The rendering is triggered by orchestrator (Airflow or Dagster) after the data pipeline has been sucsessfully completed.\nFor demonstration purpose, a histogram of year of birth is plotted using OMOP-CDM patient dataset."
  },
  {
    "objectID": "posts/elt_omop/index.html#orchestration-and-scheduling",
    "href": "posts/elt_omop/index.html#orchestration-and-scheduling",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "Orchestration and scheduling",
    "text": "Orchestration and scheduling\n\nApache Airflow\nApache Airflow is the current standard tool for complex workflow orchestration. Although Airflow and dbt share some similarities, dbt is for transformation step, Airflow is the job scheduler for the whole project. It is difficult to grasp such one tool, let alone make both tools work together. Thanks to Cosmos by Astronomer, now it is much easier to setup and make Airflow and dbt work together more harmoniously.\nPreviously, the common way to use both tools, is just run a airflow bashoperator for dbt. It is not ideal, since it is difficult to see the DAG inside dbt. Now with Cosmo, one can monitor the whole process including the dbt DAG inside Airflow, as the screenshot for this project shown below.\n\n\n\nDagster\nDagster is another popular data pipeline orchestration tool. It is uniquely fit for data pipeline workflow, since it is based on the notion of asset driven workflow. Any upstream asset modification will automatically notify the downstreams. Unlike Airflow, even the latest data-aware scheduling feature of Airflow, cannot detect dataset changes themselves.\nAnother benefit of using Daster is its lightweight design. Only one node is needed, as comparing to Airflow, which requires four nodes (webserver, scheduler, trigerer, database)\nLatest development of Dagster, make it possible to have full observability across pipelines including what’s inside dbt, thanks to dagster-dbt"
  },
  {
    "objectID": "posts/elt_omop/index.html#summary",
    "href": "posts/elt_omop/index.html#summary",
    "title": "Data pipeline ELT project from Synthea to OMOP CDM",
    "section": "Summary",
    "text": "Summary\nThe main purpose of this project is to showcasing the knowledge and skills involved in producing a tailor-made and well-managed workflow using state of the art healthcare data solutions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Penguins\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nFlorida Math Grade 3 data analysis\n\n\n\n\n\n\n\ndata science\n\n\n\n\n\n\n\n\n\n\n\nDec 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\nData pipeline ELT project from Synthea to OMOP CDM\n\n\n\n\n\n\n\ndata engineering\n\n\n\n\n\n\n\n\n\n\n\nNov 17, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is Lei’s personal website powered by Quarto and github page.\nMore about me:\nGoogle Scholar Page"
  },
  {
    "objectID": "posts/fl_math/index.html",
    "href": "posts/fl_math/index.html",
    "title": "Florida Math Grade 3 data analysis",
    "section": "",
    "text": "import duckdb\nimport pandas as pd\n\nto execute jupyter notebook inplace in cli\njupyter nbconvert –execute ./posts/fl_math/index.ipynb –inplace\n\n%load_ext sql\nconn = duckdb.connect()\n%sql conn --alias duckdb\n%config SqlMagic.displaylimit = 50\n\n\nmath_xls = pd.read_excel(\"25Math03SRSSpring23.xls\", skiprows=4, usecols=\"A:H\")\nduckdb.sql(\"CREATE TABLE math_xls AS SELECT * FROM math_xls\")\nmath_xls.iloc[0].to_dict()\n\n{'District Number': 0,\n 'District Name': 'STATE TOTALS',\n 'School Number': 0,\n 'School Name': 'GRADE 03',\n 'Grade': 3,\n 'Number of Students': 221011,\n 'Mean  Scale Score ': 300,\n 'Percentage in\\nLevel 3 or Above': 59}\n\n\n\n%%sql\ndescribe\nselect *\nFROM math_xls\n\nRunning query in 'duckdb'\n\n\n\n\n\n\n\n\n\n\n\n\n\ncolumn_name\ncolumn_type\nnull\nkey\ndefault\nextra\n\n\n\n\nDistrict Number\nBIGINT\nYES\nNone\nNone\nNone\n\n\nDistrict Name\nVARCHAR\nYES\nNone\nNone\nNone\n\n\nSchool Number\nBIGINT\nYES\nNone\nNone\nNone\n\n\nSchool Name\nVARCHAR\nYES\nNone\nNone\nNone\n\n\nGrade\nBIGINT\nYES\nNone\nNone\nNone\n\n\nNumber of Students\nBIGINT\nYES\nNone\nNone\nNone\n\n\nMean Scale Score\nVARCHAR\nYES\nNone\nNone\nNone\n\n\nPercentage in\nLevel 3 or Above\nVARCHAR\nYES\nNone\nNone\nNone\n\n\n\n\n\n\n%%sql\n\nselect \"District Name\", \"School Name\", \"Mean  Scale Score \"\nfrom math_xls\nwhere \"District Name\" = 'HILLSBOROUGH'\norder by \"Mean  Scale Score \" desc\n\nRunning query in 'duckdb'\n\n\n\n\n\nDistrict Name\nSchool Name\nMean Scale Score\n\n\n\n\nHILLSBOROUGH\nDUNBAR ELEMENTARY MAGNET SCHOOL\n323\n\n\nHILLSBOROUGH\nBRYANT ELEMENTARY SCHOOL\n323\n\n\nHILLSBOROUGH\nMITCHELL ELEMENTARY SCHOOL\n321\n\n\nHILLSBOROUGH\nBEVIS ELEMENTARY SCHOOL\n321\n\n\nHILLSBOROUGH\nROOSEVELT ELEMENTARY SCHOOL\n320\n\n\nHILLSBOROUGH\nCHILES ELEMENTARY SCHOOL\n320\n\n\nHILLSBOROUGH\nGRADY ELEMENTARY SCHOOL\n320\n\n\nHILLSBOROUGH\nMABRY ELEMENTARY SCHOOL\n320\n\n\nHILLSBOROUGH\nGORRIE ELEMENTARY SCHOOL\n319\n\n\nHILLSBOROUGH\nMACFARLANE PARK ELEMENTARY MAGNET SCHOOL\n319\n\n\nHILLSBOROUGH\nMCKITRICK ELEMENTARY SCHOOL\n319\n\n\nHILLSBOROUGH\nSTOWERS ELEMENTARY SCHOOL\n318\n\n\nHILLSBOROUGH\nFISHHAWK CREEK ELEMENTARY SCHOOL\n317\n\n\nHILLSBOROUGH\nCHIARAMONTE ELEMENTARY SCHOOL\n316\n\n\nHILLSBOROUGH\nPRIDE ELEMENTARY SCHOOL\n315\n\n\nHILLSBOROUGH\nHUNTER'S GREEN ELEMENTARY SCHL\n315\n\n\nHILLSBOROUGH\nCLARK ELEMENTARY SCHOOL\n315\n\n\nHILLSBOROUGH\nNORTHWEST ELEMENTARY SCHOOL\n314\n\n\nHILLSBOROUGH\nBOYETTE SPRINGS ELEM. SCHOOL\n314\n\n\nHILLSBOROUGH\nDEER PARK ELEMENTARY SCHOOL\n313\n\n\nHILLSBOROUGH\nRAMPELLO K-8 MAGNET SCHOOL\n313\n\n\nHILLSBOROUGH\nRIVERVIEW ACADEMY OF MATH AND SCIENCE\n313\n\n\nHILLSBOROUGH\nMANISCALCO K-8 SCHOOL\n312\n\n\nHILLSBOROUGH\nROLAND PARK K-8 MAGNET SCHOOL\n312\n\n\nHILLSBOROUGH\nAPOLLO BEACH ELEMENTARY SCHOOL\n312\n\n\nHILLSBOROUGH\nWINTHROP CHARTER SCHOOL\n312\n\n\nHILLSBOROUGH\nDOROTHY C YORK PK-8 MAGNET SCHOOL\n311\n\n\nHILLSBOROUGH\nHAMMOND ELEMENTARY SCHOOL\n311\n\n\nHILLSBOROUGH\nWESTCHASE ELEMENTARY SCHOOL\n311\n\n\nHILLSBOROUGH\nSUNLAKE ACADEMY OF MATH AND SCIENCES\n311\n\n\nHILLSBOROUGH\nLUTZ PREPARATORY SCHOOL\n310\n\n\nHILLSBOROUGH\nRIVERHILLS ELEMENTARY MAGNET SCHOOL\n309\n\n\nHILLSBOROUGH\nKIDS COMMUNITY COLLEGE RIVERVIEW SOUTH (K-12)\n309\n\n\nHILLSBOROUGH\nRCMA WIMAUMA COMMUNITY ACADEMY\n308\n\n\nHILLSBOROUGH\nVALRICO ELEMENTARY SCHOOL\n308\n\n\nHILLSBOROUGH\nCITRUS PARK ELEMENTARY SCHOOL\n308\n\n\nHILLSBOROUGH\nLANIER ELEMENTARY SCHOOL\n307\n\n\nHILLSBOROUGH\nVALRICO LAKE ADVANTAGE ACADEMY\n307\n\n\nHILLSBOROUGH\nBUCKHORN ELEMENTARY SCHOOL\n307\n\n\nHILLSBOROUGH\nBALLAST POINT ELEMENTARY SCHL\n306\n\n\nHILLSBOROUGH\nLUTZ K-8 SCHOOL\n306\n\n\nHILLSBOROUGH\nLAKE MAGDALENE ELEM. SCHOOL\n305\n\n\nHILLSBOROUGH\nSCHWARZKOPF ELEMENTARY SCHOOL\n305\n\n\nHILLSBOROUGH\nMULLER ELEMENTARY MAGNET SCHOOL\n305\n\n\nHILLSBOROUGH\nCIMINO ELEMENTARY SCHOOL\n304\n\n\nHILLSBOROUGH\nHERITAGE ELEMENTARY SCHOOL\n304\n\n\nHILLSBOROUGH\nANDERSON ELEMENTARY SCHOOL\n304\n\n\nHILLSBOROUGH\nLITHIA SPRINGS ELEM. SCHOOL\n304\n\n\nHILLSBOROUGH\nTINKER K-8 SCHOOL\n304\n\n\nHILLSBOROUGH\nLIMONA ELEMENTARY SCHOOL\n304\n\n\n\n\nTruncated to displaylimit of 50."
  },
  {
    "objectID": "posts/penguins/index.html",
    "href": "posts/penguins/index.html",
    "title": "Penguins",
    "section": "",
    "text": "A simple example based on Allison Horst’s Palmer Penguins dataset. Here we look at how penguin body mass varies across both sex and species (use the provided inputs to filter the dataset by bill length and island):\n\nviewof bill_length_min = Inputs.range(\n  [32, 50], \n  {value: 35, step: 1, label: \"Bill length (min):\"}\n)\nviewof islands = Inputs.checkbox(\n  [\"Torgersen\", \"Biscoe\", \"Dream\"], \n  { value: [\"Torgersen\", \"Biscoe\"], \n    label: \"Islands:\"\n  }\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlotData\n\n\n\nPlot.rectY(filtered, \n  Plot.binX(\n    {y: \"count\"}, \n    {x: \"body_mass_g\", fill: \"species\", thresholds: 20}\n  ))\n  .plot({\n    facet: {\n      data: filtered,\n      x: \"sex\",\n      y: \"species\",\n      marginRight: 80\n    },\n    marks: [\n      Plot.frame(),\n    ]\n  }\n)\n\n\n\n\n\n\n\n\n\nInputs.table(filtered)\n\n\n\n\n\n\n\n\n\n\ndata = FileAttachment(\"penguins.csv\").csv({ typed: true })\n\n\n\n\n\n\n\nfiltered = data.filter(function(penguin) {\n  return bill_length_min &lt; penguin.bill_length_mm &&\n         islands.includes(penguin.island);\n})"
  }
]