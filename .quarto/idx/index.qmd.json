{"title":"Portfolio project","markdown":{"yaml":{"title":"Portfolio project","format":{"html":{"code-fold":true,"code-summary":"Show the code"}}},"headingText":"Extraction process","containsRefs":false,"markdown":"\n\nTL;DR You can find the project code on GitHub\n\nThis is Lei's work-in-progress portfolio project, illustrating a realistic data pipeline implemented from extracting electronic medical records (EMR), various medical vocabularies, loading onto a database and conducting transformation using dbt, while the workflow is orchestrated, scheduled and monitored using Apache airflow.  \n\nThe pipeline process is documented using diagram as code tool [Diagrams](https://diagrams.mingrammer.com/)\n\n```{python}\nfrom diagrams import Diagram, Cluster\nfrom diagrams.onprem.analytics import Dbt\nfrom diagrams.onprem.database import Postgresql\nfrom diagrams.onprem.workflow import Airflow\nfrom diagrams.generic.storage import Storage\n\nwith Diagram(\"Synthea OMOP CDM ELT Workflow\", show=False) as diag:\n\n    with Cluster(\"Orchestration & Scheduler\"):    \n        Airflow('Apache Airflow')     \n\n    with Cluster(\"Data Pipeline\"):\n        [Storage(\"Synthea \"), Storage(\"Athena Vocab\")] >> Postgresql(\"Postgres\") >> Dbt(\"dbt\") \n\n    \ndiag\n```\n\n\n\n\nOpen sourced [Synthea](https://synthea.mitre.org/) project provides the capability of generating realistic synthetic EMR data, and downloadable data in various formats. The csv files has been used in this project.\n\n[Athena](https://athena.ohdsi.org/search-terms/start) is one of the open sourced tools provided by [OHDSI – Observational Health Data Sciences and Informatics](https://www.ohdsi.org/), greatly simplied the process of converting various medical codes to standard codes. For this project, I downloaded a subset of the codes listed on the website.\n\n## Loading process\n\nAt the moment, the csv files from both Synthea and Athena were put in the dbt seeds folder. A better approach is to load the large csv files directly to the database, only store small crosswalks csv in seeds folder.\n\n## Transformation process\n\ndbt were used for the whole transformation process. It is currently the stands for the T step in ETL/ELT process.\n\nThe sql codes were adopted from [ETL-Synthea-dbt](https://github.com/sidataplus/ETL-Synthea-dbt/tree/dcb9c262bad32e5d04cd73e4f34a01d884f3e71c) which in turn were adopted from OHDSI tool [OHDSI/ETL-Synthea](https://github.com/OHDSI/ETL-Synthea).\n\nThis process is complex in nature. To have a good understanding, I went over following resources:\n\n- [The Book of OHDSI](https://ohdsi.github.io/TheBookOfOhdsi/)\n- [OHDSI - YouTube](https://www.youtube.com/@OHDSI)\n- [Data Standardization – OHDSI](https://www.ohdsi.org/data-standardization/)\n\n## Orchestration and scheduling\n\nApache Airflow is the current standard tool for complex workflow orchestration. Although Airflow and dbt share some similarities, dbt is for transformation step, Airflow is the job scheduler for the whole project. It is difficult to grasp such one tool, let alone make both tools work together. Thanks to [Cosmos by Astronomer](https://www.astronomer.io/cosmos/), now it is much easier to setup and make Airflow and dbt work together more harmoniously.\n\nPreviously, the common way to use both tools, is just run a airflow bashoperator for dbt. It not ideal, since it is difficult to see the DAG inside dbt. Now with Cosmo, one can monitor the whole process including the dbt DAG inside Airflow, as the screenshot for this project shown below.\n\n![](airflow_screenshot.png)\n\n\n\n\n","srcMarkdownNoYaml":"\n\nTL;DR You can find the project code on GitHub\n\nThis is Lei's work-in-progress portfolio project, illustrating a realistic data pipeline implemented from extracting electronic medical records (EMR), various medical vocabularies, loading onto a database and conducting transformation using dbt, while the workflow is orchestrated, scheduled and monitored using Apache airflow.  \n\nThe pipeline process is documented using diagram as code tool [Diagrams](https://diagrams.mingrammer.com/)\n\n```{python}\nfrom diagrams import Diagram, Cluster\nfrom diagrams.onprem.analytics import Dbt\nfrom diagrams.onprem.database import Postgresql\nfrom diagrams.onprem.workflow import Airflow\nfrom diagrams.generic.storage import Storage\n\nwith Diagram(\"Synthea OMOP CDM ELT Workflow\", show=False) as diag:\n\n    with Cluster(\"Orchestration & Scheduler\"):    \n        Airflow('Apache Airflow')     \n\n    with Cluster(\"Data Pipeline\"):\n        [Storage(\"Synthea \"), Storage(\"Athena Vocab\")] >> Postgresql(\"Postgres\") >> Dbt(\"dbt\") \n\n    \ndiag\n```\n\n\n\n## Extraction process\n\nOpen sourced [Synthea](https://synthea.mitre.org/) project provides the capability of generating realistic synthetic EMR data, and downloadable data in various formats. The csv files has been used in this project.\n\n[Athena](https://athena.ohdsi.org/search-terms/start) is one of the open sourced tools provided by [OHDSI – Observational Health Data Sciences and Informatics](https://www.ohdsi.org/), greatly simplied the process of converting various medical codes to standard codes. For this project, I downloaded a subset of the codes listed on the website.\n\n## Loading process\n\nAt the moment, the csv files from both Synthea and Athena were put in the dbt seeds folder. A better approach is to load the large csv files directly to the database, only store small crosswalks csv in seeds folder.\n\n## Transformation process\n\ndbt were used for the whole transformation process. It is currently the stands for the T step in ETL/ELT process.\n\nThe sql codes were adopted from [ETL-Synthea-dbt](https://github.com/sidataplus/ETL-Synthea-dbt/tree/dcb9c262bad32e5d04cd73e4f34a01d884f3e71c) which in turn were adopted from OHDSI tool [OHDSI/ETL-Synthea](https://github.com/OHDSI/ETL-Synthea).\n\nThis process is complex in nature. To have a good understanding, I went over following resources:\n\n- [The Book of OHDSI](https://ohdsi.github.io/TheBookOfOhdsi/)\n- [OHDSI - YouTube](https://www.youtube.com/@OHDSI)\n- [Data Standardization – OHDSI](https://www.ohdsi.org/data-standardization/)\n\n## Orchestration and scheduling\n\nApache Airflow is the current standard tool for complex workflow orchestration. Although Airflow and dbt share some similarities, dbt is for transformation step, Airflow is the job scheduler for the whole project. It is difficult to grasp such one tool, let alone make both tools work together. Thanks to [Cosmos by Astronomer](https://www.astronomer.io/cosmos/), now it is much easier to setup and make Airflow and dbt work together more harmoniously.\n\nPreviously, the common way to use both tools, is just run a airflow bashoperator for dbt. It not ideal, since it is difficult to see the DAG inside dbt. Now with Cosmo, one can monitor the whole process including the dbt DAG inside Airflow, as the screenshot for this project shown below.\n\n![](airflow_screenshot.png)\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.361","theme":"cosmo","title":"Portfolio project","code-summary":"Show the code"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}